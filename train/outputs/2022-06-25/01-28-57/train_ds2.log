[2022-06-25 01:28:57,364][kospeech.utils][INFO] - model:
  architecture: deepspeech2
  hidden_dim: 1024
  dropout: 0.3
  num_encoder_layers: 3
  rnn_type: gru
  max_len: 400
  activation: hardtanh
  teacher_forcing_ratio: 1.0
  teacher_forcing_step: 0.0
  min_teacher_forcing_ratio: 1.0
  joint_ctc_attention: false
train:
  dataset: kspon
  dataset_path: ''
  transcripts_path: /Users/jongbeom.kim/Documents/ksponspeech/data/transcripts.txt
  output_unit: character
  num_epochs: 70
  batch_size: 32
  save_result_every: 1000
  checkpoint_every: 5000
  print_every: 10
  mode: train
  seed: 777
  resume: false
  num_workers: 4
  use_cuda: true
  optimizer: adam
  init_lr: 1.0e-06
  final_lr: 1.0e-06
  peak_lr: 0.0001
  init_lr_scale: 0.01
  final_lr_scale: 0.05
  max_grad_norm: 400
  warmup_steps: 400
  weight_decay: 1.0e-05
  reduction: mean

[2022-06-25 01:28:57,365][kospeech.utils][INFO] - Operating System : Darwin 20.6.0
[2022-06-25 01:28:57,377][kospeech.utils][INFO] - Processor : i386
[2022-06-25 01:28:57,378][kospeech.utils][INFO] - CUDA is available : False
[2022-06-25 01:28:57,378][kospeech.utils][INFO] - PyTorch version : 1.11.0
[2022-06-25 01:28:57,382][kospeech.utils][INFO] - split dataset start !!
